{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import math\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "import timeit\n",
    "data = pd.read_csv(\"C:/Users/fatih/Desktop/spambase.data\",header = None,sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9  ...    48     49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.00  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.00  0.132   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25 ...  0.01  0.143   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.137   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.135   \n",
       "5  0.00  0.00  0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00 ...  0.00  0.223   \n",
       "\n",
       "    50     51     52     53     54   55    56  57  \n",
       "0  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "5  0.0  0.000  0.000  0.000  3.000   15    54   1  \n",
       "\n",
       "[6 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 0:56].values\n",
    "y = data.iloc[:, 57].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.   ,  0.64 ,  0.64 ,  0.   ,  0.32 ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.64 ,  0.   ,  0.   ,  0.   ,  0.32 ,\n",
       "        0.   ,  1.29 ,  1.93 ,  0.   ,  0.96 ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.778,  0.   ,  0.   ,  3.756, 61.   ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601,)\n",
      "(3450,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "print(y.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3450, 56)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "print(X_train.shape)\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yapay_sinir_agi():\n",
    "    def __init__(self, katmanlar):\n",
    "        self.katmanlar = katmanlar\n",
    "        self.b = [np.random.randn(k, 1) for k in self.katmanlar[1:]] # bias degerleri (ilk katman haric)\n",
    "        self.W = [np.random.randn(k2, k1) for k1, k2 in zip(self.katmanlar[:-1],self.katmanlar[1:])]\n",
    "        self.H = [] # hata\n",
    "        \n",
    "        self.onlyOnce = True\n",
    "\n",
    "    def ag(self):\n",
    "        return self.W, self.b\n",
    "    \n",
    "    def ileribesleme(self, a):\n",
    "        \"\"\"Katman katman yeni a degerleri hesaplaniyor\"\"\"\n",
    "        a = self.checkDimension(a)\n",
    "        for w, b in zip(self.W, self.b):\n",
    "            z = np.dot(w, a)+b\n",
    "            a = self.sigmoid(z)\n",
    "        return a\n",
    "    \n",
    "    def geribesleme(self,X,y):\n",
    "        delta_b = [np.zeros(b.shape) for b in self.b]\n",
    "        delta_w = [np.zeros(w.shape) for w in self.W]\n",
    "        a = X; A, Z = [a], []  # A, Z degerleri\n",
    "        for w, b in zip(self.W, self.b):# z ve a degerlerini depolayalim\n",
    "            z = np.dot(w, a) + b\n",
    "            a = self.sigmoid(z)\n",
    "            Z.append(z); A.append(a)\n",
    "            \n",
    "            self.printShape(b, \"b\", w, \"w\")\n",
    "\n",
    "\n",
    "        \n",
    "        hata = A[-1] - y # En son katmandaki hata \n",
    "        delta = hata * self.sigmoid_turevi(Z[-1])\n",
    "        delta_b[-1] = delta # Son katmanda W, b'deki degisim  \n",
    "        delta_w[-1] = delta * A[-2].T # ERROR: np.dot(delta, A[-2].T)\n",
    "        \n",
    "        self.printShape(delta_b[-1], \"delta_b[-1]\", delta_w[-1], \"delta_w[-1]\")\n",
    "        \n",
    "        for k in range(2, len(self.katmanlar)): # Hatanin geriye yayilimi\n",
    "            delta = np.dot(self.W[-k+1].T, delta) * self.sigmoid_turevi(Z[-k])\n",
    "            delta_b[-k] = delta\n",
    "            delta_w[-k] = delta * A[-k-1].T # ERROR: np.dot(delta, A[-k-1].T)\n",
    "            \n",
    "            self.printShape(delta_b[-k], \"delta_b[-k]\", delta_w[-k], \"delta_w[-k]\")\n",
    "        self.onlyOnce = False\n",
    "\n",
    "        return (delta_b, delta_w)  \n",
    "    \n",
    "    def hata(self,X,y):\n",
    "        a = self.ileribesleme(X)\n",
    "        if a.shape != y.shape: print(hata)\n",
    "        return np.sum(np.power(a-y,2))\n",
    "    \n",
    "    \n",
    "    def gradyan_inis(self, X_train, y_train, alpha, number_steps):\n",
    "        print(\"X_train.shape\",X_train.shape)\n",
    "        print(\"y_train.shape\",y_train.shape)\n",
    "        for s in range(number_steps):\n",
    "            i, m = 0,X_train.shape[1]\n",
    "            X, y = X_train[:,[i]], y_train[:,[i]]\n",
    "            tum_delta_b, tum_delta_w = self.geribesleme(X,y)\n",
    "            hata = self.hata(X,y)\n",
    "            \n",
    "            for i in range(1,m): # Tum X kolonlari icin\n",
    "                X, y = X_train[:,[i]], y_train[:,[i]]\n",
    "                delta_b, delta_w = self.geribesleme(X,y)\n",
    "                tum_delta_b = [tdb + db for tdb, db in zip(tum_delta_b, delta_b)]\n",
    "                tum_delta_w = [tdw + dw for tdw, dw in zip(tum_delta_w, delta_w)]\n",
    "                hata += self.hata(X,y)\n",
    "                    \n",
    "            tum_delta_b = [alpha*tdb for tdb in tum_delta_b]\n",
    "            tum_delta_w = [alpha*tdw for tdw in tum_delta_w]\n",
    "        \n",
    "            self.W = [w - dw for w, dw in zip(self.W, tum_delta_w)]\n",
    "            self.b = [b - db for b, db in zip(self.b, tum_delta_b)]\n",
    "            self.H.append(hata/m)\n",
    "\n",
    "    def fit(self, X_train, y_train, alpha = 0.0000001, number_steps = 1000):  \n",
    "        X_train = X_train.T # X verileri kolon=gozlem, satir=oznitelik (alistigimizin tersi)\n",
    "        y_train = self.checkOutputLayer(y_train)\n",
    "        return self.gradyan_inis(X_train, y_train, alpha, number_steps)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        if self.katmanlar[-1] == 1 : \n",
    "            tahmin = self.ileribesleme(X_test.T) >= 0.5  \n",
    "            t = tahmin.astype('int')\n",
    "            return t[0]\n",
    "        return np.argmax(self.ileribesleme(X_test.T), axis= 0)\n",
    "    \n",
    "    #### Yardimci Fonksiyonlar\n",
    "    def sigmoid(self,z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    def sigmoid_turevi(self,z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "    def checkDimension(self,x):\n",
    "        if x.ndim == 1: return x.reshape(x.shape[0], 1)\n",
    "        return x\n",
    "    def checkOutputLayer(self, y):\n",
    "        if len(set(y)) == 2: return y.reshape(1,y.shape[0])\n",
    "        y_vec = np.zeros((len(set(y)),len(y)))\n",
    "        for c,r in enumerate(y):  y_vec[r,c] = 1\n",
    "        return y_vec\n",
    "    def printShape(self, b, bs, w, ws):\n",
    "        if self.onlyOnce == True: print(bs, \".shape: \",b.shape,\" \", ws ,\".shape: \",w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runNN(alpha = 0.001, number_steps = 100):\n",
    "    # Fitting Our Own Neural Network to the Training set\n",
    "    start_time = timeit.default_timer()\n",
    "    ysa = yapay_sinir_agi(katmanlar = [56,12,1])\n",
    "    ysa.fit(X_train_scaled,y_train, alpha, number_steps)\n",
    "    \n",
    "    tahmin = ysa.predict(X_test_scaled)\n",
    "    \n",
    "    \n",
    "    print(\"Time: \", timeit.default_timer() - start_time)\n",
    "    \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    cm = confusion_matrix(y_test, tahmin)\n",
    "    print(\"\\t\\t\\t\\t\\t---Our Own Neural Network---\")\n",
    "    print(\"confusion_matrix:\\n\", cm)\n",
    "    print(\"accuracy_score: \", accuracy_score(y_test, tahmin))\n",
    "    plt.plot(ysa.H)\n",
    "    print(\"\\nMatrix Shape\")\n",
    "    for w, b in zip(ysa.W, ysa.b):\n",
    "        print(\"b.shape: \",b.shape,\" w.shape: \",w.shape)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (56, 3450)\n",
      "y_train.shape (1, 3450)\n",
      "b .shape:  (12, 1)   w .shape:  (12, 56)\n",
      "b .shape:  (1, 1)   w .shape:  (1, 12)\n",
      "delta_b[-1] .shape:  (1, 1)   delta_w[-1] .shape:  (1, 12)\n",
      "delta_b[-k] .shape:  (12, 1)   delta_w[-k] .shape:  (12, 56)\n",
      "Time:  280.2999511266381\n",
      "\t\t\t\t\t---Our Own Neural Network---\n",
      "confusion_matrix:\n",
      " [[648  43]\n",
      " [ 42 418]]\n",
      "accuracy_score:  0.9261511728931364\n",
      "\n",
      "Matrix Shape\n",
      "b.shape:  (12, 1)  w.shape:  (12, 56)\n",
      "b.shape:  (1, 1)  w.shape:  (1, 12)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runNN(alpha = 0.03, number_steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "3450/3450 [==============================] - 0s 122us/step - loss: 0.4629 - acc: 0.8261\n",
      "Epoch 2/7\n",
      "3450/3450 [==============================] - 0s 78us/step - loss: 0.2246 - acc: 0.9272\n",
      "Epoch 3/7\n",
      "3450/3450 [==============================] - 0s 75us/step - loss: 0.2010 - acc: 0.9336\n",
      "Epoch 4/7\n",
      "3450/3450 [==============================] - 0s 75us/step - loss: 0.1882 - acc: 0.9365\n",
      "Epoch 5/7\n",
      "3450/3450 [==============================] - 0s 79us/step - loss: 0.1793 - acc: 0.9374\n",
      "Epoch 6/7\n",
      "3450/3450 [==============================] - 0s 79us/step - loss: 0.1722 - acc: 0.9377\n",
      "Epoch 7/7\n",
      "3450/3450 [==============================] - 0s 79us/step - loss: 0.1669 - acc: 0.9377\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 12, kernel_initializer = 'uniform', activation = 'relu', input_dim = 56))\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train_scaled, y_train, batch_size = 10, epochs = 7)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class agent():\n",
    "    def __init__(self,ID, katmanlar=[56,12,1]):\n",
    "        self.katmanlar = katmanlar\n",
    "        self.ID=ID\n",
    "        self.H = [] \n",
    "        self.W=[]\n",
    "        self.onlyOnce = True\n",
    "    \n",
    "    def feed(self,x=X_train_scaled,y=y_train):\n",
    "        self.Y=y\n",
    "        self.X=x\n",
    "        self.b = [np.random.randn(k, 1) for k in self.katmanlar[1:]] \n",
    "        self.W = [5*np.random.randn(k2, k1) for k1, k2 in zip(self.katmanlar[:-1],self.katmanlar[1:])]\n",
    "        self.score = self.performance()\n",
    "    \n",
    "\n",
    "   \n",
    "    def immitate(self,other,pr=1):\n",
    "        if np.random.rand() < pr:\n",
    "            k =  random.randint(0,(self.katmanlar[1]-1))#11\n",
    "            l =  random.randint(0,(self.katmanlar[1]-1))#11\n",
    "            self.b[0][k]=other.b[0][k]\n",
    "            self.W[0][k]=other.W[0][k]\n",
    "            self.W[1][0][l]=other.W[1][0][l]\n",
    "            self.score = self.performance()\n",
    "    \n",
    "    def innovate(self, pr = 0.1):\n",
    "        if np.random.rand() < pr: \n",
    "            k =  random.randint(0,(self.katmanlar[1]-1))\n",
    "            l =  random.randint(0,(self.katmanlar[1]-1))\n",
    "            #save1,save2=self.W[0][k],self.W[1][k][l]\n",
    "            \n",
    "            self.W[0][k] = 5*np.random.randn(self.katmanlar[0])\n",
    "            self.W[1][0][l] = 5*np.random.randn()\n",
    "            self.score = self.performance()\n",
    "    \n",
    "    def performance(self,threshold=0.5):\n",
    "        \n",
    "        abm_pred=self.predict() \n",
    "        p = abm_pred >= threshold\n",
    "        scoree=1/(1+np.sum(np.power(self.Y - p,2)))\n",
    "        \n",
    "        return scoree\n",
    "        \n",
    "    \n",
    "    def predict(self,X=X_train_scaled):\n",
    "        l1=np.zeros(self.katmanlar[1])\n",
    "        m,n=X.shape\n",
    "        res=np.zeros(m)\n",
    "        for k in range(m):#750 kez\n",
    "            for i in range(self.katmanlar[1]):#12 kez\n",
    "                WT=self.W[0][i]\n",
    "                l2=np.dot(X[k],WT)+self.b[0][i]\n",
    "                l1[i]=self.sigmoid(np.sum(l2))\n",
    "            l2=self.sigmoid(np.dot(self.W[1][0],l1))\n",
    "            res[k]=l2\n",
    "        return res\n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    def relu(self,x):\n",
    "        return max(0, x)\n",
    "\n",
    "              \n",
    "class abmNeural():\n",
    "    def __init__(self, X=X_train_scaled, y=y_train, N = 100, time = 1000,katmanlar=[58,12,1]):\n",
    "        self.X, self.y, self.N, self.time = X, y, N, time\n",
    "        self.population = [agent(i,katmanlar=[56,12,1]) for i in range(self.N)]\n",
    "        \n",
    "    def feed(self):\n",
    "        for A in self.population:\n",
    "            A.feed(self.X, self.y) \n",
    "    \n",
    "    def social_optimisation(self):\n",
    "        #self.feed()\n",
    "        for i in range(self.time):\n",
    "            iA, iB = np.random.choice(range(self.N), 2, replace=False)\n",
    "            A, B = self.population[iA], self.population[iB]\n",
    "            \n",
    "            if A.score > B.score: \n",
    "                B.immitate(A)\n",
    "                A.innovate();B.innovate(pr=1)\n",
    "                \n",
    "            else: \n",
    "                A.immitate(B)\n",
    "                A.innovate(pr=1);B.innovate()\n",
    "                           \n",
    "    def social_optimisation2(self):\n",
    "        #self.feed()\n",
    "        A=self.best_agent()\n",
    "        \n",
    "        for i in range(self.time):\n",
    "            iB = np.random.choice(range(self.N), replace=False)\n",
    "            B = self.population[iB]\n",
    "            \n",
    "            B.immitate(A)\n",
    "            A.innovate();B.innovate(pr=1)\n",
    "            \n",
    "    def best_agent(self):   \n",
    "        scores = [A.score for A in self.population]\n",
    "        ibest = scores.index(max(scores))\n",
    "        return self.population[ibest]\n",
    "        \n",
    "\n",
    "    \n",
    "    def predict(self, X_test=X_test_scaled, threshold = 0.5):\n",
    "        \n",
    "        res=self.best_agent().predict(X=X_test)\n",
    "        m,n=X_test.shape\n",
    "        \n",
    "        return res\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1151,)\n"
     ]
    }
   ],
   "source": [
    "abm= abmNeural(X=X_train_scaled, y=y_train, N = 10000, time = 10000,katmanlar=[56,12,1])\n",
    "abm.feed()\n",
    "abm_predWithoutImitation=abm.predict(X_test)\n",
    "abm.social_optimisation()\n",
    "abm_pred=abm.predict(X_test)\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print(abm_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "abm2= abmNeural(X=X_train_scaled, y=y_train, N = 100, time = 100,katmanlar=[56,12,1])\n",
    "abm2.population=abm.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n=len(abm_pred)\n",
    "\n",
    "for i in range(n):\n",
    "    if abm_pred[i]< 0.5:\n",
    "        abm_pred[i]=0\n",
    "    else :\n",
    "        abm_pred[i]=1\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t---Our Own Neural Network with ABM---\n",
      "confusion_matrix:\n",
      " [[631  60]\n",
      " [425  35]]\n",
      "accuracy_score:  0.578627280625543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, abm_pred)\n",
    "print(\"\\t\\t\\t\\t---Our Own Neural Network with ABM---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, abm_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method abmNeural.social_optimisation2 of <__main__.abmNeural object at 0x00000227944F6AC8>>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abm2.social_optimisation2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    if abm_predWithoutImitation[i]< 0.5:\n",
    "        abm_predWithoutImitation[i]=0\n",
    "    else :\n",
    "        abm_predWithoutImitation[i]=1\n",
    "\n",
    "for i in range(n):\n",
    "    if abm_predv3[i]< 0.5:\n",
    "        abm_predv3[i]=0\n",
    "    else :\n",
    "        abm_predv3[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t---Our Own Neural Network without imitation---\n",
      "confusion_matrix:\n",
      " [[631  60]\n",
      " [425  35]]\n",
      "accuracy_score:  0.578627280625543\n",
      "\t\t\t\t---Our Own Neural Network with ABMv3---\n",
      "confusion_matrix:\n",
      " [[631  60]\n",
      " [425  35]]\n",
      "accuracy_score:  0.46568201563857514\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\t\\t\\t---Our Own Neural Network without imitation---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, abm_predWithoutImitation))\n",
    "print(\"\\t\\t\\t\\t---Our Own Neural Network with ABMv3---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, abm_predv3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
